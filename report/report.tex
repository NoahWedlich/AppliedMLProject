\documentclass[11pt]{article}

% Packages
\usepackage[margin=1in]{geometry}
\usepackage{amsmath, amssymb}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{fancyhdr}
\usepackage{titlesec}

% Header/Footer
\pagestyle{fancy}
\fancyhf{}
\rhead{ML Project Report}
\lhead{Your Name}
\cfoot{\thepage}

% Section formatting
\titleformat{\section}{\large\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}{\normalsize\bfseries}{\thesubsection}{1em}{}

% Title
\title{\textbf{Machine Learning Project Report}}
\author{Valentin Herrmann, Noah Wedlich \\
Applied Machine Learning in Python – LMU Munich}
\date{\today}

\begin{document}

% NOTE: specification:
% The report should clearly summarize:
%     What task was addressed
%     How it was approached
%     Why certain methods/experiments were chosen
%     Key results and interpretations
% Include relevant figures (e.g., plots, tables).

\maketitle

\section{Task Overview}
% Briefly describe the dataset or model you worked on, the goal of the project, and why the task is challenging. For example, challenges may include complex preprocessing, large dataset size, class imbalance, poor performance of baseline approaches, or the need for more complex models to achieve good results.

In this project we tested if common models like kernel svms, perceptrons as well as decision tree ensembles suffer from the bias-variance tradeoff. For this purpose we trained and tested the models on simple datasets like concentric bands, interleaving half-moons, spirals and separated Gaussian clusters to produce signs of underfitting and especially of overfitting.
% too slow ⇒ multiprocessing
% getting fitting learning_rate
% creating proper visualizations

\section{Methods}
% Explain the methods you implemented or analyzed. Include relevant equations:

% \[\min_{\mathbf{w}} \quad \frac{1}{2} \|\mathbf{w}\|^2 + C \sum_{i=1}^n \xi_i \]

% Mention any design decisions or implementation notes.
% TunableModel

\subsection{Implementation}
The implementation of this project can essentially be divided into two parts: the tunable models and the samplers, both of which we will shortly describe here. We chose an object-oriented approach
to allow for easy extension and reuse of the code and to integrate with the Courselib.
\begin{description}
    \item[Tunable Model:] This class provides a convenient way to create and train models on all (or a subset of) the hyperparameter combinations specified. When initialized, it receives
        a subclass of the Courselib \texttt{TrainableModel} class and a dictionary mapping parameter names to their possible values. When training the model, it will instantiate a model
        for each combination of hyperparameters and train it on the given data. Optionally, one can also provide a validator function which can limit the training to a subset of the
        combinations. Since the different models are independent of each other, the training is parallelized using Python's \texttt{multiprocessing} module. We also utilize queues to
        communicate with the main process, which allows us to display the training progress in real-time. If an optimizer is used for training, we will further wrap it to provide
        granular progress updates.
    \item[Samplers:] The samplers are used to generate the datasets on which the models are trained. The subclasses provided here will sample from a distribution on $S\times L\subseteq [-1, 1]^2\times \mathbb{N}$
        where $S$ is some 2D shape and $L$ is a set of labels. The Samplers also provide methods to apply pre- and postprocessing to the data, which can be used to transform the data into a suitable format for training
        and to apply transformations to the data after sampling. This allows to easily test the robustness of models using domain shifts or label noise.
\end{description}

\section{Experiments and Results}
% Present your results. Use figures, tables, and metrics:

% show used data

% \begin{figure}[h]
%     \centering
%     \includegraphics[width=0.5\textwidth]{figures/accuracy_curve.png}
%     \caption{Training/validation accuracy over epochs.}
% \end{figure}

\section{Discussion}
% Summarize key findings, insights, or issues. Optionally, suggest future work or limitations.

\end{document}
